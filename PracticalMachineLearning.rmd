---
title: "Practical Machine Learning - course project"
author: "Peter Slezák"
date: "Thursday, November 20, 2014"
output: html_document
---

##Introduction
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. The data set consists of a readings from accelerometers attached to the subjects performing different exercises. The sensors were attached on the belt, forearm, arm, and dumbell. The goal of this project is to predict the manner in which these subjects did the exercises. The dependent variable we want to predict is the **'classe'** variable in the training data set.

##Getting and Cleaning Data
First, Read the training **pml-training.csv** and testing **pml-testing.csv** data files. Then remove all variables with more than 20% of missing values. Finally, remove the first seven variables that represent ID variables and some technical information about the measurements. These variables are irrelevant for the prediction. Do this for both training and testing data set.

```{r, cache=TRUE, message=FALSE}
library(caret)
library(randomForest)

#read data
setwd("D:/Dropbox/Data Science - materialy")
training1<-read.csv("pml-training.csv", na.strings=c("", "NA", "NULL"))
test1<-read.csv("pml-testing.csv", na.strings=c("", "NA", "NULL"))

#remove variables that have to manny missing values (>20%)
nalim<-nrow(training1)*0.2
nalim2<-nrow(test1)*0.2
training1<-training1[, colSums(is.na(training1))<nalim]
test1<-test1[, colSums(is.na(test1))<nalim2]

#remove columns - X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window
training1<-training1[,-c(1:7)]
test1<-test1[,-c(1:7)]
```

Now split the training data set in two parts (70:30) per cent in size. The first part (**training**) will be used for the creation of machine learning algorithm and the second part (**testing**) of the data set for the out-of-sample error estimation. Initialize the pseudorandom number generator for with *set.seed()* function because of the reproducibility of the subsequent computation.

```{r, cache=TRUE}
#split the training data
set.seed(10)
inTrain <- createDataPartition(training1$classe, p=0.7, list=F)
training <- training1[inTrain,]
testing <- training1[-inTrain,]
```

##Modelling
I created the prediction model using the random forest algorithm, since it is one of the top performing algorithms in the terms of accuracy. For the sake of computational speed I used direct calling of the *randomForest()* function. (Thank you guys from the [discussion forum][1] for this suggestion.)

[1]: https://class.coursera.org/predmachlearn-007/forum/thread?thread_id=76

```{r, cache=TRUE}
#random forest
#fit2<-train(classe~., data=training, method="rf")
fit3<-randomForest(classe~.,data=training)
fit3
```

We can see that [the out-of-bag (oob) error][2] estimate is very low *0.56%*. It is an unbiased estimate of the test set error.

[2]: https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr

```{r, cache=TRUE}
#show confusion matrix for validating data set.
prd<-predict(fit3, newdata=testing)
confusionMatrix(prd,testing$classe)
```
Also there is no need for cross-validation when using random forests, I computed the model out-of-sample accuracy as well. The out-of-sample accuracy was *99.59%*.

#Generating files for the submission part of the assignment
```{r, cache=TRUE}
#generate submission text files using the script provided
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
x <- test1
titles<-names(test1)
x <- x[titles[titles!='classe']]
answers<-predict(fit3, newdata=x)
pml_write_files(answers)
```
These answers were submitted to the website for grading and all answers were correct.